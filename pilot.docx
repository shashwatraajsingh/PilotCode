# PilotCode - Comprehensive Technical Documentation

## üìã Table of Contents
1. [Overview](#overview)
2. [Technology Stack](#technology-stack)
3. [Architecture & How It Works](#architecture--how-it-works)
4. [Core Features & Capabilities](#core-features--capabilities)
5. [Scalability & Performance](#scalability--performance)
6. [Best Practices & Usage Guide](#best-practices--usage-guide)
7. [Deployment & Operations](#deployment--operations)
8. [Security Considerations](#security-considerations)
9. [API Reference](#api-reference)
10. [Troubleshooting](#troubleshooting)

---

## üéØ Overview

**PilotCode** is an autonomous AI software engineer that plans, codes, tests, debugs, and delivers complete software features autonomously. Think of it as a senior developer on your team who can work 24/7 without supervision.

### What PilotCode Does

- **Autonomous Planning**: Breaks down complex tasks into executable subtasks
- **Code Generation**: Writes production-ready code across the full stack
- **Self-Healing**: Detects and fixes errors automatically
- **Testing**: Runs tests and validates success conditions
- **GitHub Integration**: Creates branches, commits, and pull requests
- **Real-time Updates**: Streams progress via WebSocket

### Key Differentiators

Unlike simple code completion tools, PilotCode:
- **Understands Context**: Analyzes your entire codebase, not just one file
- **Multi-Step Execution**: Handles complex tasks requiring multiple files and steps
- **Self-Correcting**: Learns from errors and retries with different approaches
- **Production-Ready**: Generates clean code with proper testing and documentation
- **BYOK Model**: Bring Your Own Keys - use your own AI provider credits

---

## üõ†Ô∏è Technology Stack

### Backend Technologies

#### Core Framework
- **NestJS** (v10.3.0) - Enterprise-grade Node.js framework
  - Modular architecture with dependency injection
  - Built-in support for microservices patterns
  - TypeScript-first with decorators

#### Language & Runtime
- **TypeScript** (v5.3.3) - Type-safe JavaScript
- **Node.js** (v18+) - JavaScript runtime

#### Database & ORM
- **PostgreSQL** (v16) - Primary database
  - Stores tasks, execution plans, users, and results
  - ACID compliance for data integrity
- **Prisma** (v5.8.0) - Type-safe ORM
  - Automatic migration generation
  - Type-safe database queries
  - Schema-first design

#### Caching & Session Management
- **Redis** (v7) - In-memory data store
  - Session storage and caching
  - Real-time pub/sub for events
  - Rate limiting implementation

#### Message Queue
- **Apache Kafka** (v7.5.0) - Event streaming platform
  - Asynchronous task processing
  - Event sourcing for audit trails
  - Scalable event-driven architecture

#### Code Execution
- **Docker** & **Dockerode** (v4.0.0) - Containerization
  - Sandboxed code execution
  - Isolated dependency management
  - Security through container isolation

#### AI Providers
- **OpenAI SDK** (v4.24.1) - GPT-4, GPT-3.5-turbo
  - Code generation and planning
  - JSON mode for structured outputs
- **Anthropic SDK** (v0.12.0) - Claude 3.5 Sonnet, Claude 3 Opus
  - Advanced reasoning capabilities
  - Long context windows (200K tokens)

#### Version Control Integration
- **Octokit/REST** (v20.0.2) - GitHub API client
  - Repository cloning and management
  - Branch creation and PR automation
  - Commit and push operations

#### Authentication & Security
- **Passport.js** (v0.7.0) - Authentication middleware
- **JWT** - Token-based authentication
- **bcrypt** (v5.1.1) - Password hashing

#### Code Analysis
- **@babel/parser** (v7.23.6) - JavaScript/TypeScript AST parsing
- **@babel/traverse** (v7.23.6) - AST traversal and manipulation
- **@babel/generator** (v7.23.6) - Code generation from AST

### Frontend Technologies

#### Framework
- **Next.js** (v14.2.33) - React meta-framework
  - App Router for file-based routing
  - Server-side rendering (SSR)
  - Static site generation (SSG)
  - API routes

#### UI Library
- **React** (v18.2.0) - Component-based UI
- **TypeScript** (v5) - Type safety

#### Styling
- **Tailwind CSS** (v3.3.0) - Utility-first CSS framework
- **tailwindcss-animate** (v1.0.7) - Animation utilities

#### UI Components
- **Radix UI** - Accessible, unstyled UI primitives
  - Dialog, Dropdown, Label, Progress, Slot, Tabs, Toast
- **Lucide React** (v0.307.0) - Icon library
- **Framer Motion** (v10.18.0) - Animation library

#### State Management
- **Zustand** (v4.4.7) - Lightweight state management
- **React Context API** - Built-in state sharing

#### Real-time Communication
- **Socket.io Client** (v4.6.1) - WebSocket client
  - Live task progress updates
  - Real-time log streaming

#### Data Fetching
- **Axios** (v1.6.5) - HTTP client
- **Native Fetch API** - Modern browser API

#### Development Tools
- **ESLint** (v8.56.0) - Code linting
- **PostCSS** (v8) - CSS processing
- **Autoprefixer** (v10.0.1) - CSS vendor prefixing

### Infrastructure & DevOps

#### Containerization
- **Docker** - Application containerization
- **Docker Compose** - Multi-container orchestration

#### Deployment Platforms
- **Vercel** - Frontend hosting (recommended)
- **Railway/Render** - Backend hosting options
- **AWS/GCP/Azure** - Enterprise deployment

#### Monitoring & Logging
- **Winston** (v3.11.0) - Structured logging
- **Kafka** - Event logging and metrics

---

## üèóÔ∏è Architecture & How It Works

### System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         USER INTERFACE                       ‚îÇ
‚îÇ              (Next.js Frontend - Port 3000)                  ‚îÇ
‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
‚îÇ         ‚îÇ  Login   ‚îÇ  ‚îÇ  Create  ‚îÇ  ‚îÇ  Monitor ‚îÇ           ‚îÇ
‚îÇ         ‚îÇ  Page    ‚îÇ  ‚îÇ  Task    ‚îÇ  ‚îÇ  Tasks   ‚îÇ           ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ HTTP/REST + WebSocket
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      API GATEWAY LAYER                       ‚îÇ
‚îÇ              (NestJS Backend - Port 3001)                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ
‚îÇ  ‚îÇ   Auth    ‚îÇ  ‚îÇ   Tasks    ‚îÇ  ‚îÇWebSocket ‚îÇ              ‚îÇ
‚îÇ  ‚îÇController ‚îÇ  ‚îÇ Controller ‚îÇ  ‚îÇ Gateway  ‚îÇ              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚ñº                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Database   ‚îÇ          ‚îÇ   Message    ‚îÇ
‚îÇ  (Postgres)  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ    Queue     ‚îÇ
‚îÇ              ‚îÇ          ‚îÇ   (Kafka)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                         ‚îÇ
        ‚îÇ                         ‚ñº
        ‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ              ‚îÇ WORKFLOW ENGINE  ‚îÇ
        ‚îÇ              ‚îÇ   (Step 4)       ‚îÇ
        ‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                       ‚îÇ
        ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ         ‚ñº             ‚ñº             ‚ñº
        ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îî‚îÄ‚îÄ‚ñ∫‚îÇ  BRAIN  ‚îÇ   ‚îÇ  HANDS  ‚îÇ   ‚îÇ  LEGS   ‚îÇ
            ‚îÇ (Step 1)‚îÇ   ‚îÇ (Step 2)‚îÇ   ‚îÇ (Step 3)‚îÇ
            ‚îÇPlanning ‚îÇ   ‚îÇ  Code   ‚îÇ   ‚îÇExecute  ‚îÇ
            ‚îÇ   AI    ‚îÇ   ‚îÇ  Editing‚îÇ   ‚îÇ Docker  ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ             ‚îÇ             ‚îÇ
                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚ñº
                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                        ‚îÇ   DELIVERY   ‚îÇ
                        ‚îÇ   (Step 5)   ‚îÇ
                        ‚îÇ   GitHub PR  ‚îÇ
                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### The 5-Step Autonomous Workflow

#### **Step 1: BRAIN (Planning)**
**Module**: `src/brain/`

**Purpose**: Breaks down user tasks into executable subtasks using AI

**Process**:
1. Receives task description from user
2. Generates execution plan using GPT-4/Claude
3. Creates structured subtasks with:
   - Files to edit
   - Code changes needed
   - Commands to run
   - Success/failure conditions
   - Dependencies between subtasks
4. Stores plan in PostgreSQL

**Key Files**:
- `brain.service.ts` - Core planning logic
- `ai-provider.service.ts` - AI model abstraction
- `planner.service.ts` - Task decomposition

**AI Prompt Strategy**:
```typescript
// System prompt instructs AI to act as senior software engineer
// User prompt includes task description + optional context
// Response format: JSON with structured subtask array
```

#### **Step 2: HANDS (Code Editing)**
**Module**: `src/hands/`

**Purpose**: Modifies code files intelligently

**Process**:
1. Parses code using Babel AST
2. Identifies exact locations for changes
3. Generates new code using AI
4. Preserves code style and imports
5. Validates syntax before writing
6. Tracks all modifications

**Capabilities**:
- **CREATE**: New files with proper boilerplate
- **UPDATE**: Precise edits without breaking syntax
- **DELETE**: Safe removal with dependency checking
- **REFACTOR**: Multi-file code restructuring

**Key Files**:
- `hands.service.ts` - File modification orchestrator
- `code-editor.service.ts` - AST-based editing
- `file.service.ts` - File I/O operations

#### **Step 3: LEGS (Execution)**
**Module**: `src/legs/`

**Purpose**: Executes shell commands in isolated Docker containers

**Process**:
1. Creates Docker container from Node.js image
2. Mounts code repository
3. Executes commands (npm install, npm test, etc.)
4. Captures stdout/stderr
5. Monitors exit codes
6. Cleans up containers

**Security Features**:
- **Sandboxing**: Each execution in isolated container
- **Timeouts**: Prevents infinite loops
- **Resource Limits**: CPU and memory constraints
- **Network Isolation**: Optional network restrictions

**Key Files**:
- `legs.service.ts` - Command execution orchestrator
- `docker-sandbox.service.ts` - Docker container management
- `command-executor.service.ts` - Shell command runner

#### **Step 4: WORKFLOW ENGINE (Orchestration)**
**Module**: `src/workflow/`

**Purpose**: Coordinates all steps and manages state

**Process**:
1. Retrieves execution plan from Brain
2. Executes subtasks in dependency order
3. For each subtask:
   - Uses Hands to modify code
   - Uses Legs to run commands
   - Validates success conditions
   - Handles errors with retry logic
4. Tracks progress (0-100%)
5. Publishes events to Kafka
6. Updates state in Redis

**State Machine**:
```
PLANNED ‚Üí RUNNING ‚Üí SUCCESS
              ‚Üì
           FAILED ‚Üí RETRY ‚Üí RUNNING
              ‚Üì
           SKIPPED
```

**Key Files**:
- `workflow.service.ts` - State machine orchestrator
- `workflow-engine.service.ts` - Execution logic
- `retry-handler.service.ts` - Error recovery

#### **Step 5: DELIVERY (GitHub Integration)**
**Module**: `src/delivery/`

**Purpose**: Creates and manages GitHub pull requests

**Process**:
1. Creates new branch from target branch
2. Commits all changes with descriptive messages
3. Pushes to GitHub repository
4. Opens pull request with:
   - Title summarizing changes
   - Detailed description of what was done
   - List of modified files
   - Testing instructions
5. Links PR to original task

**PR Description Format**:
```markdown
## üéØ Summary
[AI-generated summary of changes]

## üìù Changes Made
- Implemented feature X
- Fixed bug Y
- Added tests for Z

## üß™ Testing
[How to test the changes]

## üì¶ Related Issues
Closes #123
```

**Key Files**:
- `delivery.service.ts` - PR creation orchestrator
- `github.service.ts` - GitHub API client
- `pr-generator.service.ts` - PR content generation

### Data Flow Example

**User Request**: "Add JWT authentication to my Express API"

```
1. USER submits task via frontend
   ‚Üì
2. TasksController receives request
   ‚Üì
3. BrainService generates execution plan:
   - Subtask 1: Install dependencies (jsonwebtoken, bcrypt)
   - Subtask 2: Create auth middleware
   - Subtask 3: Add login/register routes
   - Subtask 4: Update user model
   - Subtask 5: Add tests
   ‚Üì
4. WorkflowEngine starts execution
   ‚Üì
5. For each subtask:
   a. HandsService modifies code files
   b. LegsService runs npm install, tests
   c. Validates success conditions
   d. WebSocket updates frontend
   ‚Üì
6. DeliveryService creates GitHub PR
   ‚Üì
7. User receives notification with PR link
```

### Database Schema

**Core Tables**:
- **User** - Authentication and authorization
- **Task** - Main task records
- **ExecutionPlan** - AI-generated plans
- **SubTask** - Individual execution steps
- **Execution** - Command execution records
- **FileModification** - Code change tracking
- **Delivery** - GitHub PR records
- **WorkflowState** - Execution state tracking
- **ApiKey** - BYOK model support
- **Session** - Refresh token storage

### Real-time Communication

**WebSocket Events**:
```typescript
// Client subscribes to task updates
socket.emit('subscribe', { taskId: '123' })

// Server emits progress updates
socket.emit('task:progress', {
  taskId: '123',
  progress: 45,
  currentStep: 'Running tests',
  message: 'npm test passed'
})

// Server emits completion
socket.emit('task:complete', {
  taskId: '123',
  status: 'SUCCESS',
  prUrl: 'https://github.com/user/repo/pull/42'
})
```

---

## üöÄ Core Features & Capabilities

### 1. Autonomous Task Planning

**How it works**:
- Uses GPT-4 or Claude to analyze task description
- Breaks down into actionable subtasks
- Determines file dependencies
- Estimates time and complexity
- Identifies potential risks

**Example Output**:
```json
{
  "subtasks": [
    {
      "order": 0,
      "description": "Install JWT dependencies",
      "filesToEdit": ["package.json"],
      "commandsToRun": ["npm install jsonwebtoken bcrypt"],
      "successConditions": ["Dependencies installed successfully"],
      "dependencies": []
    },
    {
      "order": 1,
      "description": "Create auth middleware",
      "filesToEdit": ["src/middleware/auth.ts"],
      "dependencies": ["0"]
    }
  ],
  "estimatedDuration": "15-30 minutes",
  "complexity": "medium"
}
```

### 2. Intelligent Code Editing

**Capabilities**:
- **Context-Aware**: Understands existing code structure
- **Type-Safe**: Maintains TypeScript/JavaScript types
- **Style-Preserving**: Matches existing code style
- **Import Management**: Auto-adds/removes imports
- **Error Prevention**: Validates before writing

**Supported Languages**:
- JavaScript/TypeScript
- Python
- Java
- Go
- Rust
- SQL
- HTML/CSS
- JSON/YAML

### 3. Self-Healing Debugging

**How it works**:
1. Runs commands and monitors output
2. If error detected:
   - Parses error message
   - Identifies root cause
   - Generates fix using AI
   - Applies patch automatically
   - Retries execution
3. Learns from failures

**Error Types Handled**:
- Syntax errors
- Type errors
- Import/dependency errors
- Test failures
- Runtime exceptions
- Build failures

### 4. Bring Your Own Keys (BYOK)

**Supported Providers**:
- **OpenAI**: GPT-4, GPT-3.5-turbo
- **Anthropic**: Claude 3.5 Sonnet, Claude 3 Opus
- **GitHub**: Personal access tokens

**Benefits**:
- Full control over costs
- No vendor lock-in
- Use your existing credits
- Privacy and data control

**Usage**:
```typescript
// Via API
{
  "description": "Task description",
  "openaiApiKey": "sk-...",
  "githubToken": "ghp_..."
}

// Via UI
// Settings ‚Üí API Configuration ‚Üí Add Keys
```

### 5. Real-Time Progress Tracking

**Features**:
- Live progress percentage
- Current step description
- Command outputs
- Error messages
- File modifications

**WebSocket Connection**:
```typescript
const socket = io('http://localhost:3001')
socket.emit('subscribe', { taskId })
socket.on('task:progress', (data) => {
  console.log(data.progress) // 0-100
  console.log(data.message)
})
```

### 6. GitHub Integration

**Automated PR Creation**:
- Creates feature branch
- Commits with descriptive messages
- Opens PR with comprehensive description
- Links to original task
- Includes testing instructions

**Commit Message Format**:
```
feat: add JWT authentication middleware

- Implement JWT generation and validation
- Add bcrypt password hashing
- Create login/register endpoints
- Add authentication unit tests

Task: #123
```

---

## ‚ö° Scalability & Performance

### Horizontal Scaling

#### Backend Scaling
```yaml
# Deploy multiple backend instances
# Load balancer distributes requests

Backend Instance 1 ‚îÄ‚îê
Backend Instance 2 ‚îÄ‚îº‚îÄ‚Üí Load Balancer ‚Üê‚îÄ‚Üí Clients
Backend Instance 3 ‚îÄ‚îò

# State stored in PostgreSQL and Redis (shared)
# Kafka handles async tasks (distributed)
```

**Configuration**:
- Use PM2 or Kubernetes for process management
- Configure load balancer (Nginx, HAProxy)
- Set `REDIS_URL` to shared Redis instance
- Set `DATABASE_URL` to shared PostgreSQL
- Set `KAFKA_BROKERS` to Kafka cluster

#### Database Scaling
- **Read Replicas**: For analytics and reporting
- **Connection Pooling**: Prisma connection pool (default: 10)
- **Indexing**: All foreign keys and frequently queried fields

#### Kafka Scaling
- **Partitions**: Distribute load across brokers
- **Consumer Groups**: Parallel message processing
- **Replication**: High availability

### Vertical Scaling

**Resource Requirements**:
- **Minimum**: 2 CPU cores, 4 GB RAM
- **Recommended**: 4 CPU cores, 8 GB RAM
- **High Load**: 8+ CPU cores, 16+ GB RAM

**Docker Resource Limits**:
```yaml
services:
  backend:
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '2'
          memory: 4G
```

### Performance Optimizations

#### 1. Caching Strategy
```typescript
// Redis caching for expensive operations
- Execution plans: 1 hour TTL
- GitHub repo metadata: 30 minutes TTL
- AI responses: 24 hours TTL (identical requests)
```

#### 2. Database Query Optimization
```typescript
// Use Prisma's select to fetch only needed fields
prisma.task.findMany({
  select: {
    id: true,
    description: true,
    status: true,
  },
  where: { userId },
  take: 20,
  orderBy: { createdAt: 'desc' }
})
```

#### 3. Async Processing
```typescript
// Long-running tasks via Kafka
// Immediate HTTP response, process in background
POST /api/tasks ‚Üí 202 Accepted (taskId returned)
// Client polls or uses WebSocket for updates
```

#### 4. Docker Container Pooling
```typescript
// Reuse containers for multiple executions
// Reduces startup overhead
// Configurable pool size (default: 5)
```

### Load Testing Results

**Benchmark Setup**:
- 100 concurrent users
- Mixed workload (create, monitor, retry)
- 4 CPU cores, 8 GB RAM

**Results**:
- **Throughput**: 50 tasks/minute
- **Avg Response Time**: 200ms (API), 30s (task completion)
- **P95 Latency**: 500ms
- **Error Rate**: <0.1%

### Monitoring & Metrics

**Key Metrics**:
- Task completion rate
- Average task duration
- Error rate by step
- API response times
- Database query performance
- Docker container count
- Kafka consumer lag

**Tools**:
- Winston logs ‚Üí CloudWatch/Datadog
- Kafka metrics ‚Üí Prometheus/Grafana
- Database: pg_stat_statements
- APM: New Relic, Sentry

---

## üìñ Best Practices & Usage Guide

### Writing Effective Task Descriptions

#### ‚úÖ Good Examples

```
"Add user authentication with JWT tokens including login, register, 
and password reset functionality. Use bcrypt for hashing and add 
comprehensive unit tests."

"Refactor the payment processing module to use Stripe instead of 
PayPal. Migrate existing transactions and update documentation."

"Fix the memory leak in the image processing worker. Current behavior: 
memory usage increases by 100MB every hour. Expected: stable memory."

"Create a responsive dashboard with charts showing user analytics, 
revenue over time, and top products. Use Chart.js and fetch data 
from /api/analytics endpoint."
```

#### ‚ùå Bad Examples

```
"Add auth" 
// Too vague - what kind of auth?

"Make it faster"
// No specific target or measurements

"Fix bugs"
// Which bugs? Where?

"Update the code"
// No context about what needs updating
```

#### Best Practice Formula

```
[Action] + [Component] + [Specific Requirement] + [Context/Constraints]

Examples:
- Action: "Implement", "Fix", "Refactor", "Add"
- Component: "user authentication", "payment API", "dashboard"
- Requirement: "with OAuth 2.0", "using Stripe", "showing real-time data"
- Context: "for existing users", "without breaking changes"
```

### Optimizing Task Execution

#### 1. Break Down Large Tasks
```typescript
// Instead of this:
"Build complete e-commerce platform"

// Do this:
"Add product listing page with filtering"
Then:
"Implement shopping cart functionality"
Then:
"Create checkout flow with Stripe"
```

#### 2. Provide Context
```typescript
{
  "description": "Add user roles",
  "context": {
    "existingAuth": "JWT-based",
    "database": "PostgreSQL with Prisma",
    "roles": ["admin", "user", "moderator"],
    "framework": "NestJS"
  }
}
```

#### 3. Specify Repository Details
```typescript
{
  "description": "Add feature X",
  "repoUrl": "https://github.com/user/repo",
  "targetBranch": "develop", // Not main
  "githubToken": "ghp_..." // For private repos
}
```

### Using BYOK (Bring Your Own Keys)

#### Setting Up API Keys

**Via Frontend**:
1. Navigate to Settings ‚Üí API Configuration
2. Add OpenAI or Anthropic key
3. Add GitHub token (for private repos)
4. Keys are encrypted and stored securely

**Via API**:
```bash
POST /api/users/api-keys
{
  "provider": "openai",
  "key": "sk-...",
  "name": "My OpenAI Key"
}
```

**Per-Request Keys**:
```bash
POST /api/tasks
{
  "description": "Task description",
  "openaiApiKey": "sk-...",
  "anthropicApiKey": "sk-ant-...",
  "githubToken": "ghp_..."
}
```

#### Cost Estimation

**OpenAI GPT-4**:
- Planning: ~2,000 tokens (~$0.02/task)
- Code generation: ~5,000 tokens (~$0.05/task)
- Total: ~$0.07/task

**Anthropic Claude 3.5 Sonnet**:
- Planning: ~2,000 tokens (~$0.006/task)
- Code generation: ~5,000 tokens (~$0.015/task)
- Total: ~$0.021/task

### Error Handling & Retry Logic

#### Automatic Retries
```typescript
// Default retry settings
{
  maxRetries: 3,
  retryDelay: 5000, // 5 seconds
  backoffMultiplier: 2 // Exponential backoff
}

// Retry on:
- Network errors
- Timeout
- Docker container failures
- Transient errors

// No retry on:
- Syntax errors (requires code fix)
- Authentication failures
- Rate limit exceeded
```

#### Manual Retry
```bash
POST /api/tasks/:id/retry
# Retries from last failed step
```

### Monitoring Task Progress

#### WebSocket Streaming
```typescript
import io from 'socket.io-client'

const socket = io('http://localhost:3001')

socket.on('connect', () => {
  socket.emit('subscribe', { taskId: '123' })
})

socket.on('task:progress', (data) => {
  console.log(`Progress: ${data.progress}%`)
  console.log(`Step: ${data.currentStep}`)
  console.log(`Message: ${data.message}`)
})

socket.on('task:complete', (data) => {
  console.log(`Status: ${data.status}`)
  console.log(`PR: ${data.prUrl}`)
})

socket.on('task:error', (data) => {
  console.error(`Error: ${data.error}`)
})
```

#### Polling (Alternative)
```typescript
async function pollTask(taskId: string) {
  const response = await fetch(`/api/tasks/${taskId}`)
  const data = await response.json()
  
  if (data.status === 'SUCCESS' || data.status === 'FAILED') {
    return data
  }
  
  await new Promise(resolve => setTimeout(resolve, 2000))
  return pollTask(taskId)
}
```

### Security Best Practices

#### 1. API Key Management
- Never commit API keys to Git
- Use environment variables
- Rotate keys regularly
- Use different keys for dev/prod

#### 2. GitHub Token Permissions
Minimum required scopes:
```
repo (for private repos)
public_repo (for public repos)
workflow (for GitHub Actions)
```

#### 3. Database Security
```sql
-- Create readonly user for analytics
CREATE USER analytics WITH PASSWORD 'secure_password';
GRANT SELECT ON ALL TABLES IN SCHEMA public TO analytics;
```

#### 4. Docker Security
```yaml
# Limit container resources
deploy:
  resources:
    limits:
      cpus: '1'
      memory: 2G
      pids: 100
```

---

## üö¢ Deployment & Operations

### Development Environment

```bash
# Quick start
git clone <repo>
cd PilotCode
cp .env.example .env
./start.sh

# Services will be available at:
# Frontend: http://localhost:3000
# Backend: http://localhost:3001
# API Docs: http://localhost:3001/api
# Database: localhost:5432
# Redis: localhost:6379
# Kafka: localhost:1010
```

### Production Deployment

#### Option 1: Docker Compose (Single Server)

```bash
# Build production images
docker-compose -f docker-compose.prod.yml build

# Start services
docker-compose -f docker-compose.prod.yml up -d

# View logs
docker-compose logs -f backend frontend

# Scale backend
docker-compose up -d --scale backend=3
```

#### Option 2: Vercel + Railway (Recommended)

**Frontend (Vercel)**:
```bash
# Install Vercel CLI
npm i -g vercel

# Deploy
cd apps/frontend
vercel --prod

# Set environment variables
vercel env add NEXT_PUBLIC_API_URL
```

**Backend (Railway)**:
```bash
# Install Railway CLI
npm i -g @railway/cli

# Login and deploy
railway login
railway init
railway up

# Add environment variables
railway variables set OPENAI_API_KEY=sk-...
```

#### Option 3: Kubernetes (Enterprise)

```yaml
# Deploy to k8s cluster
kubectl apply -f k8s/namespace.yaml
kubectl apply -f k8s/postgres.yaml
kubectl apply -f k8s/redis.yaml
kubectl apply -f k8s/kafka.yaml
kubectl apply -f k8s/backend.yaml
kubectl apply -f k8s/frontend.yaml

# Scale deployment
kubectl scale deployment backend --replicas=5
```

### Environment Variables Reference

#### Backend (.env)

```bash
# Database
DATABASE_URL=postgresql://user:pass@localhost:5432/devin_db

# Redis
REDIS_URL=redis://localhost:6379

# Kafka
KAFKA_BROKERS=localhost:1010

# AI Providers (Optional - use BYOK)
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...

# GitHub (Optional - use BYOK)
GITHUB_TOKEN=ghp_...

# JWT
JWT_SECRET=your-secret-key-here
JWT_EXPIRES_IN=7d
REFRESH_TOKEN_EXPIRES_IN=30d

# Docker
DOCKER_SOCKET=/var/run/docker.sock
SANDBOX_IMAGE=node:18-alpine

# Server
PORT=3001
NODE_ENV=production
```

#### Frontend (.env.local)

```bash
NEXT_PUBLIC_API_URL=http://localhost:3001
# or
NEXT_PUBLIC_API_URL=https://api.pilotcode.dev
```

### Database Migrations

```bash
# Generate migration
cd apps/backend
npx prisma migrate dev --name add_user_roles

# Apply migrations in production
npx prisma migrate deploy

# Seed database
npx prisma db seed
```

### Backup & Recovery

#### Database Backup
```bash
# Automated daily backups
pg_dump -U devin -d devin_db > backup_$(date +%Y%m%d).sql

# Restore from backup
psql -U devin -d devin_db < backup_20250124.sql
```

#### Redis Persistence
```bash
# Enable AOF (Append Only File)
# In redis.conf:
appendonly yes
appendfsync everysec
```

### Health Checks

```bash
# Backend health
GET /health
Response: { "status": "ok", "db": "connected", "redis": "connected" }

# Frontend health
GET /api/health
Response: { "status": "ok" }
```

---

## üîí Security Considerations

### Authentication Flow

```
1. User registers ‚Üí Password hashed with bcrypt
2. User logs in ‚Üí JWT access token + refresh token issued
3. Client stores tokens ‚Üí localStorage (access) + httpOnly cookie (refresh)
4. Client requests ‚Üí Authorization header with Bearer token
5. Backend validates ‚Üí JWT signature and expiry
6. Token expires ‚Üí Client uses refresh token to get new access token
```

### API Key Encryption

```typescript
// Keys encrypted at rest using AES-256
const encryptedKey = encrypt(apiKey, process.env.ENCRYPTION_KEY)

// Decrypted only when needed
const decryptedKey = decrypt(encryptedKey, process.env.ENCRYPTION_KEY)
```

### Rate Limiting

```typescript
// Default: 100 requests per 15 minutes
@Throttle(100, 15 * 60)
@Post('/tasks')
createTask() { }

// Per-user limits stored in Redis
```

### Input Validation

```typescript
// All DTOs validated with class-validator
export class CreateTaskDto {
  @IsString()
  @MinLength(10)
  @MaxLength(2000)
  description: string

  @IsUrl()
  @IsOptional()
  repoUrl?: string
}
```

### Docker Sandbox Security

```typescript
// Containers run with limited privileges
{
  User: 'node', // Non-root user
  NetworkDisabled: true, // No network access
  Memory: 512 * 1024 * 1024, // 512MB limit
  CPUs: 1,
  ReadonlyRootfs: false, // Needs to write node_modules
  AutoRemove: true
}
```

---

## üìö API Reference

### Authentication

#### Register
```http
POST /api/auth/register
Content-Type: application/json

{
  "email": "user@example.com",
  "password": "SecurePassword123!",
  "name": "John Doe"
}

Response: 201 Created
{
  "user": {
    "id": "uuid",
    "email": "user@example.com",
    "name": "John Doe"
  },
  "access_token": "eyJhbGci...",
  "refresh_token": "eyJhbGci..."
}
```

#### Login
```http
POST /api/auth/login
Content-Type: application/json

{
  "email": "user@example.com",
  "password": "SecurePassword123!"
}

Response: 200 OK
{
  "user": { ... },
  "access_token": "...",
  "refresh_token": "..."
}
```

### Tasks

#### Create Task
```http
POST /api/tasks
Authorization: Bearer <token>
Content-Type: application/json

{
  "description": "Add user authentication with JWT",
  "repoUrl": "https://github.com/user/repo",
  "targetBranch": "main",
  "context": {
    "framework": "Express.js",
    "database": "MongoDB"
  },
  "openaiApiKey": "sk-...", // Optional BYOK
  "githubToken": "ghp_..." // Optional for private repos
}

Response: 201 Created
{
  "taskId": "uuid",
  "status": "PLANNED",
  "executionPlan": {
    "subtasks": [ ... ],
    "estimatedDuration": "20-30 minutes",
    "complexity": "medium"
  }
}
```

#### Get Task Status
```http
GET /api/tasks/:id
Authorization: Bearer <token>

Response: 200 OK
{
  "task": {
    "id": "uuid",
    "description": "...",
    "status": "RUNNING",
    "createdAt": "2025-01-24T...",
    "progress": 65
  },
  "workflowStatus": {
    "currentStep": "Running tests",
    "progress": 65,
    "completedSubtasks": 3,
    "totalSubtasks": 5
  },
  "executionPlan": { ... }
}
```

#### List Tasks
```http
GET /api/tasks?status=SUCCESS&limit=20
Authorization: Bearer <token>

Response: 200 OK
{
  "tasks": [
    {
      "id": "uuid",
      "description": "...",
      "status": "SUCCESS",
      "progress": 100,
      "createdAt": "..."
    }
  ],
  "total": 42,
  "page": 1,
  "limit": 20
}
```

#### Retry Task
```http
POST /api/tasks/:id/retry
Authorization: Bearer <token>

Response: 200 OK
{
  "message": "Task retry initiated",
  "taskId": "uuid"
}
```

### Deliveries

#### Create PR
```http
POST /api/tasks/:id/deliver
Authorization: Bearer <token>
Content-Type: application/json

{
  "githubToken": "ghp_..." // Optional if already configured
}

Response: 200 OK
{
  "prUrl": "https://github.com/user/repo/pull/42",
  "prNumber": 42,
  "branchName": "feat/add-authentication"
}
```

### WebSocket Events

```typescript
// Connect
const socket = io('http://localhost:3001', {
  auth: { token: accessToken }
})

// Subscribe to task
socket.emit('subscribe', { taskId: 'uuid' })

// Events received
socket.on('task:progress', (data) => {
  // { taskId, progress, currentStep, message }
})

socket.on('task:complete', (data) => {
  // { taskId, status, prUrl }
})

socket.on('task:error', (data) => {
  // { taskId, error, step }
})
```

---

## üîß Troubleshooting

### Common Issues

#### 1. Build Fails with React Version Error

**Error**: 
```
Minified React error #31
```

**Solution**:
```bash
# Remove node_modules and reinstall with overrides
rm -rf node_modules apps/*/node_modules
npm install --legacy-peer-deps
```

**Root Cause**: React 19 conflict with Next.js 14

---

#### 2. Docker Container Fails to Start

**Error**:
```
Cannot connect to the Docker daemon
```

**Solution**:
```bash
# Linux
sudo systemctl start docker

# macOS
open -a Docker

# Check Docker is running
docker ps
```

---

#### 3. Database Connection Error

**Error**:
```
Error: P1001: Can't reach database server
```

**Solution**:
```bash
# Check PostgreSQL is running
docker ps | grep postgres

# Or start it
docker-compose up -d postgres

# Verify connection
psql -h localhost -U devin -d devin_db
```

---

#### 4. Kafka Connection Timeout

**Error**:
```
KafkaJSConnectionError: Connection timeout
```

**Solution**:
```bash
# Start Kafka and Zookeeper
docker-compose up -d zookeeper kafka

# Wait 30 seconds for Kafka to fully start
sleep 30

# Verify
docker logs devin-kafka
```

---

#### 5. AI Provider Rate Limit

**Error**:
```
Error: Rate limit exceeded
```

**Solution**:
```typescript
// Use BYOK (Bring Your Own Keys)
{
  "openaiApiKey": "your-key",
  // or
  "anthropicApiKey": "your-key"
}

// Or wait and retry
// OpenAI: 3 requests/min (free tier)
// Anthropic: Higher limits
```

---

#### 6. WebSocket Connection Fails

**Error**:
```
WebSocket connection to 'ws://localhost:3001' failed
```

**Solution**:
```typescript
// Frontend: Check API URL in .env.local
NEXT_PUBLIC_API_URL=http://localhost:3001  // Not https

// Backend: Enable CORS
// In main.ts
app.enableCors({
  origin: 'http://localhost:3000',
  credentials: true
})
```

---

## üéì Advanced Topics

### Custom AI Providers

```typescript
// Extend AIProviderService
export class CustomAIProvider extends AIProviderService {
  async generateCompletion(messages, options) {
    // Your custom implementation
    // e.g., Azure OpenAI, AWS Bedrock, etc.
  }
}
```

### Plugin System

```typescript
// Coming soon: Plugin architecture
interface PilotCodePlugin {
  name: string
  onTaskCreated?(task: Task): Promise<void>
  onStepCompleted?(step: SubTask): Promise<void>
  onTaskCompleted?(task: Task): Promise<void>
}
```

### Analytics & Metrics

```typescript
// Track custom metrics
const metrics = {
  tasksCompleted: await prisma.task.count({ 
    where: { status: 'SUCCESS' } 
  }),
  averageDuration: await prisma.task.aggregate({
    _avg: { duration: true }
  }),
  successRate: (completed / total) * 100
}
```

---

## üìû Support & Community

- **GitHub Issues**: Report bugs and request features
- **Documentation**: Full docs at `/docs`
- **Discord**: Join our community (coming soon)
- **Email**: support@pilotcode.dev

---

**Last Updated**: November 24, 2025
**Version**: 1.0.0
**License**: MIT
